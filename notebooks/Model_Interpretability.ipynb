{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrixTJvtr8nP"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install shap lime transformers torch torchvision\n",
        "\n",
        "import torch\n",
        "from transformers import XLMRobertaForTokenClassification, DistilBertForTokenClassification, BertForTokenClassification\n",
        "from transformers import XLMRobertaTokenizer, DistilBertTokenizer, BertTokenizer\n",
        "import shap\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import numpy as np\n",
        "\n",
        "# Load your models and tokenizers\n",
        "model_name_xlm = 'xlm-roberta-base'  # XLM-Roberta\n",
        "model_name_distil = 'distilbert-base-multilingual-cased'  # DistilBERT\n",
        "\n",
        "tokenizer_xlm = XLMRobertaTokenizer.from_pretrained(model_name_xlm)\n",
        "tokenizer_distil = DistilBertTokenizer.from_pretrained(model_name_distil)\n",
        "\n",
        "# Load models\n",
        "model_xlm = XLMRobertaForTokenClassification.from_pretrained(model_name_xlm)\n",
        "model_distil = DistilBertForTokenClassification.from_pretrained(model_name_distil)\n",
        "\n",
        "# Set models to evaluation mode\n",
        "model_xlm.eval()\n",
        "model_distil.eval()\n",
        "\n",
        "# Sample tokenized input data\n",
        "sample_data = [\"John Smith visited New York City.\", \"The river bank near the bank of America was flooded.\"]\n",
        "\n",
        "# Function to tokenize input\n",
        "def tokenize_input(text):\n",
        "    return tokenizer_xlm(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# SHAP Implementation\n",
        "def explain_with_shap(model, text):\n",
        "    # Tokenize input\n",
        "    tokenized_data = tokenize_input(text)\n",
        "\n",
        "    # Define a function to make predictions\n",
        "    def predict_fn(input_ids):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)\n",
        "            logits = outputs.logits\n",
        "            return torch.softmax(logits, dim=2).numpy()  # Get probabilities\n",
        "\n",
        "    # Create explainer\n",
        "    explainer = shap.Explainer(predict_fn, tokenized_data['input_ids'])\n",
        "\n",
        "    # Compute SHAP values\n",
        "    shap_values = explainer(tokenized_data['input_ids'])\n",
        "\n",
        "    # Plot SHAP summary\n",
        "    shap.summary_plot(shap_values, feature_names=tokenizer_xlm.convert_ids_to_tokens(tokenized_data['input_ids'][0].tolist()))\n",
        "\n",
        "# LIME Implementation\n",
        "def explain_with_lime(model, text):\n",
        "    # Define a function to make predictions\n",
        "    def predict_fn(texts):\n",
        "        predictions = []\n",
        "        for text in texts:\n",
        "            inputs = tokenizer_distil(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs['input_ids'])\n",
        "                logits = outputs.logits\n",
        "                predictions.append(torch.softmax(logits, dim=2).numpy())\n",
        "        return np.array(predictions)\n",
        "\n",
        "    explainer = LimeTextExplainer(class_names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'])\n",
        "    explanation = explainer.explain_instance(text, predict_fn, num_features=10)\n",
        "    explanation.show_in_notebook(text=text)\n",
        "\n",
        "# Explain the models\n",
        "print(\"SHAP Explanation for XLM-Roberta:\")\n",
        "explain_with_shap(model_xlm, sample_data[0])  # Example text for SHAP\n",
        "print(\"LIME Explanation for DistilBERT:\")\n",
        "explain_with_lime(model_distil, sample_data[1])  # Example text for LIME\n",
        "\n"
      ]
    }
  ]
}